# Task 01: 大模型简介

## 大型语言模型简介

### 大型语言模型概述

- **定义**：大型语言模型（LLM）是用于理解和生成人类语言的人工智能模型，通常包含数百亿至数千亿参数。
- **发展历程**：自20世纪90年代以来，语言建模从统计学习方法发展到引入深度学习，尤其是Transformer架构的模型，极大提升了语言处理能力。
- **常见模型**：国外有GPT-3.5、GPT-4、PaLM、Claude，国内有文心一言、讯飞星火等。
- **涌现能力**：随着模型规模的增加，LLM显示出解决复杂任务的惊人能力，如上下文学习、指令遵循、逐步推理。

### LLM 的能力与特点

- **涌现能力**：大模型中特有的能力，包括上下文学习、指令遵循和逐步推理。
- **多元应用**：大模型作为基座模型，支持广泛的应用，提升研发效率和应用表现。
- **对话统一入口**：如ChatGPT等，显示出与人类自然对话的能力。
- **技术特点**：
  - **规模巨大**：捕捉更多语言知识和复杂结构。
  - **预训练和微调**：通用语言表示学习与特定任务适应。
  - **多语言和多模态支持**：应用于多种语言和多种媒介。
  - **伦理风险**：需注意生成内容的安全性和偏见问题。
  - **高资源需求**：训练和推理需要大量计算资源。

### LLM 的应用与影响

- **自然语言处理**：提升文本理解和生成能力。
- **信息检索**：优化搜索引擎，提升检索效率。
- **计算机视觉**：助力图像与文字的综合理解。
- **通用人工智能**：推动AGI（通用人工智能）的发展，促使人们重新考虑AI的未来。


## 检索增强生成 RAG 简介

### RAG 概述

- **定义**：检索增强生成（RAG, Retrieval-Augmented Generation）是一种模型架构，通过从大型知识库中检索信息以辅助语言模型生成更准确的文本。
- **主要解决的问题**：
  - **信息偏差/幻觉**：通过实时检索减少信息错误。
  - **知识更新滞后**：通过动态检索实时数据，提供最新信息。
  - **内容不可追溯**：链接生成内容与检索到的资料，增强信任度。
  - **专业知识缺乏**：通过专业领域文档检索，提升专业回答质量。
  - **推理能力不足**：结合检索信息和生成能力，增强模型推理。
  - **场景适应性限制**：通过针对性检索，适应不同应用场景。
  - **长文本处理弱**：通过整合长文本信息，改善长内容理解。

### RAG 与微调对比

- **知识更新**：RAG 通过更新知识库实现快速响应，而微调需重训。
- **外部知识**：RAG 利用外部资源，微调将知识内化。
- **数据处理**：RAG 对数据处理要求低，微调需高质量数据集。
- **模型定制**：RAG 强于信息检索，微调强于模型行为定制。
- **可解释性**：RAG 可追溯数据源，微调较为封闭。
- **计算资源**：RAG 需额外资源支持检索，微调依赖训练数据集。
- **推理延迟**：RAG 增加检索步骤耗时，微调主要耗时于生成。
- **减少幻觉**：RAG 通过真实信息生成减少幻觉，微调依赖特定数据。
- **伦理隐私**：RAG 需注意检索数据隐私，微调需处理敏感训练数据。


## LangChain 简介

### 什么是 LangChain

LangChain 是一个开源框架，旨在简化基于大型语言模型（LLM）的应用程序开发。它提供了通用接口和工具，使得开发者能够快速构建并部署语言模型应用。

### 核心组件

LangChain 主要包括以下几个核心组件：
- **模型输入/输出（Model I/O）**：与语言模型交互的接口。
- **数据连接（Data connection）**：与应用程序数据交互的接口。
- **链（Chains）**：组合不同组件实现端到端应用。
- **记忆（Memory）**：持久化应用状态。
- **代理（Agents）**：扩展模型推理能力。
- **回调（Callbacks）**：处理复杂调用序列。


## 大模型开发的整体流程

### 定义与核心概念

大模型开发指的是以大型语言模型（LLM）为核心，结合特定数据或业务逻辑来提供独特功能的应用开发。这主要是一个工程问题，涉及调用API、数据工程、业务逻辑分解等，以发挥大模型的理解和生成能力。

### 开发流程概述

1. **目标确定**：明确应用场景、目标用户群和核心价值。
2. **功能设计**：设计应用所提供的功能和实现逻辑。
3. **架构搭建**：建立从用户输入到应用输出的整体架构。
4. **数据库搭建**：构建和维护应用所需的个性化数据库。
5. **Prompt Engineering**：设计和优化用于指导大模型的提示（Prompt）。
6. **验证迭代**：通过业务测试、分析Bad Case进行迭代优化。
7. **前后端开发**：搭建用户界面和后端服务，确保应用可交互。
8. **体验优化**：根据用户反馈持续优化应用体验。

### 实践项目：知识库助手开发

以下是基于LangChain框架开发知识库助手的简要流程：

#### 步骤一：项目规划与需求分析

- 设定项目目标：构建基于个人知识库的问答助手。
- 核心功能定义：文档上传、知识检索、问题回答等。

#### 步骤二：数据准备与向量知识库构建

- 文档处理：收集、整理并向量化用户文档。
- 数据库搭建：使用向量数据库存储和索引文档数据。

#### 步骤三：大模型集成与API连接

- 集成多个大模型，如GPT和GLM，配置API以进行数据交互。

#### 步骤四：核心功能实现与迭代

- 构建并优化Prompt Engineering以提高问答质量。
- 实现流式回答和对话记录等用户交互功能。

#### 步骤五：前端界面开发与后端服务搭建

- 使用工具如Gradio或Streamlit快速搭建前端界面。
- 确保所有用户功能均已实现并可以通过界面访问。

#### 步骤六：部署、测试与上线

- 在服务器或云平台部署应用，进行全面的生产环境测试。
- 正式上线后，收集用户反馈进行持续优化。


