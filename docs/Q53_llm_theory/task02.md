# Task02：大模型的能力篇

这一章节主要围绕 GPT3 的论文，在多个任务上对比了语言模型的性能。GPT 这种自回归的语言模型一个特别大的优势就是方便迁移并且泛化性好，正如文章标题所说`Language Models are Few-Shot Learners`

**注意：论文中并没有排除这么好的泛化性是来自模型的记忆的可能性，即可能存在数据泄露的风险。**

本章笔记主要集中在困惑度的理解上，这个概念比较重要且相对难理解。还包含了一些思考，为什么语言模型泛化的好、为什么总是 NLP 在推着别的领域走？

## 困惑度

### 直观理解

"困惑度"（Perplexity）是衡量语言模型性能的一种方式，可以用来评估模型预测语言序列（比如句子或文本）的能力。

要理解困惑度，可以想象一下你正在玩一个猜单词的游戏。

假设游戏的规则是这样的：每次你需要猜下一个单词是什么，而模型会给你提供一些可能的选项。如果模型非常好，它给出的选项中很可能就包含了正确的单词，这样你猜对的几率就很高。但如果模型不那么准确，它给出的选项中可能不包含正确的单词，或者包含了很多不相关的单词，这样你猜对的几率就会降低。

困惑度就是用来衡量这个“猜测游戏”有多困难。

如果一个语言模型的困惑度很低，意味着它提供的选项让你更容易猜对下一个单词（因为它更准确地理解了语言的规则）。相反，如果困惑度很高，说明模型提供的选项中包含了很多不准确或不相关的单词，使得猜测变得更困难。

简单来说，困惑度越低，说明语言模型预测文本的能力越强，其理解语言的水平越高。

### 计算困惑度

假设我们有一个简单的句子：“The cat sat on the mat”，我们要计算语言模型在预测这个句子时的困惑度。

1. **分割句子**：
   - 句子被分割为单词：The, cat, sat, on, the, mat。

2. **计算每个单词的条件概率**：
   - 假设我们的模型给出以下概率（这些数字是假设的，只为了示例）：
     - P(cat|The) = 0.10
     - P(sat|The cat) = 0.05
     - P(on|The cat sat) = 0.40
     - P(the|The cat sat on) = 0.30
     - P(mat|The cat sat on the) = 0.25
   - 这些概率反映了在给定之前单词的情况下，下一个单词出现的可能性。

3. **取对数并求和**：
   - 将每个概率值取自然对数，然后加总：
     - log(0.10) + log(0.05) + log(0.40) + log(0.30) + log(0.25)
   - 假设这个总和是 -8.1。

4. **求平均对数概率**：
   - 将总和除以单词数量（5个词，不包括起始的“The”）：
     - 平均 = -8.1 / 5 = -1.62

5. **计算困惑度**：
   - 最后，取这个平均对数概率的指数的倒数：
     - 困惑度 = exp(1.62) ≈ 5.06

**下面用数学语言描述上面的计算过程：**

$$
\text{ppl} = \exp\left(-\frac{1}{N}\sum_{i=1}^{N}\log(P(w_i|w_1, w_2, ..., w_{i-1}))\right)
$$

其中，$N$ 是文本中单词的数量，$P(w_i|w_1, w_2, ..., w_{i-1})$ 是在给定前面单词的情况下，第 $i$ 个单词出现的概率。

**各部分的作用：**

- **概率的意义**：每个概率值反映了模型对语言的理解程度。高概率意味着模型能准确预测下一个单词。
- **对数的作用**：对数处理是为了将乘法运算（概率相乘）转换为加法，便于计算和理解。对数还有助于平衡小概率值，避免它们在乘法中的放大效应。
- **平均对数概率**：取平均是为了消除句子长度的影响，使得不同长度的句子可以公平比较。
- **指数和倒数**：这一步是为了将结果转换为更直观、更易于理解的形式。低困惑度意味着模型更能准确预测文本，反映了高的模型性能。

困惑度越低，表示模型对文本的预测越准确。一个完美的模型会有困惑度为 1，因为它总是能准确预测下一个单词。在实际应用中，这是不可能的，因此任何实用的语言模型都会有大于 1 的困惑度。

## 思考

**1. 为什么语言模型泛化性能明显优于其他模态的模型**

- 源域与目标域的一致性。以 CV 为例，不同场景下的图像差别是很大的，比如自然图像和工业采集的图像。但是语言不一样，不同场景的语言在语义理解上差别并不大，互联网上的文本和我们日常交流的文本很一致。

- 能够很容易的将预训练模型转化成任务模型（GPT3 论文）。由于语言的特殊性，我们很容易将不同的任务通过提示统一在一起，这一点是图像、时间序列等数据不具备的。

- 训练和预测阶段模型的行为是十分一致的。这其实是前两点的交叉，是自然语言的天然优势。语言模型训练的时候就采用自回归的方式，面对不同任务时，仍然能方便的转化成自回归的方式预测。而对于图像、时间序列这些来说，我们很难定义一个合适的预训练任务使得模型能够轻松应对所有的下游任务。

**2. 为什么总感觉 NLP 领先于其他领域**

- 语言高度凝练。与之鲜明对比的是图像，MAE 论文中图像掩码 90% 以上仍然能被较好的恢复，而之前比较优秀的掩码语言模型 BERT 也才掩码 15% 而已。信息熵高，可能各种算法技巧更容易起作用。

- 语言是更高层次的认知智能，我们对于 AGI 的幻想参考的都是人脑，可能越高层的智能越适合现在的 AI 模型。